{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Artificial Intelligence (AI) has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality, personalized content such as blog posts, social media posts, product descriptions, and more. This can help businesses save time and resources on content creation.\n",
      "2. **Product Design and Development**: Generative AI can assist in the design of new products by generating 3D models, prototypes, and even entire product lines. This can reduce the time and cost associated with traditional product development methods.\n",
      "3. **Image and Video Editing**: Generative AI-powered tools can be used to edit images and videos with unprecedented ease, automating tasks such as image filtering, object removal, and video effects.\n",
      "4. **Customer Service Chatbots**: Generative AI can power chatbots that respond to customer inquiries in a more human-like way, providing personalized support and resolving issues quickly.\n",
      "5. **Recommendation Systems**: Generative AI can analyze customer behavior and preferences to generate personalized product recommendations, improving the overall shopping experience.\n",
      "6. **Marketing Automation**: Generative AI can help automate marketing tasks such as email campaigns, ad targeting, and lead generation, freeing up resources for more strategic efforts.\n",
      "7. **Predictive Maintenance**: Generative AI can be used to analyze sensor data from industrial equipment, predicting when maintenance is required and scheduling it accordingly, reducing downtime and increasing efficiency.\n",
      "8. **Fraud Detection**: Generative AI can analyze patterns in customer behavior to detect potential fraud, helping businesses protect themselves against financial losses.\n",
      "9. **Natural Language Processing (NLP)**: Generative AI can be used for NLP tasks such as language translation, sentiment analysis, and text summarization, improving communication with customers and partners.\n",
      "10. **Supply Chain Optimization**: Generative AI can analyze data from supply chains to predict demand fluctuations, optimize inventory levels, and identify potential bottlenecks.\n",
      "\n",
      "Some specific business use cases include:\n",
      "\n",
      "* **Automated content creation for news outlets**, allowing journalists to focus on fact-checking and storytelling rather than generating headlines and summaries.\n",
      "* **Personalized product recommendations for e-commerce sites**, improving customer satisfaction and driving sales.\n",
      "* **Chatbot-powered customer support** for companies, reducing the workload of human customer service representatives.\n",
      "* **Predictive maintenance scheduling** for industrial equipment, reducing downtime and increasing productivity.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources on content creation.\n",
      "2. **Image and Video Editing**: Generative AI can be used to edit images and videos, creating realistic and visually appealing content. This can be useful for businesses that need to create high-quality visual content for their websites or social media channels.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI can be used to power chatbots and virtual assistants, enabling businesses to provide 24/7 customer support and improve the overall customer experience.\n",
      "4. **Predictive Analytics**: Generative AI can be used to analyze data and make predictions about future trends and patterns. This can help businesses anticipate market changes, identify new opportunities, and make informed decisions.\n",
      "5. **Marketing Automation**: Generative AI can be used to automate marketing tasks such as email campaigns, social media posts, and ad targeting. This can help businesses save time and resources on manual marketing efforts.\n",
      "6. **Product Design**: Generative AI can be used to design new products, prototypes, and packaging designs. This can help businesses reduce the time and cost associated with product development.\n",
      "7. **Language Translation**: Generative AI can be used to translate languages in real-time, enabling businesses to communicate with customers who speak different languages.\n",
      "8. **Business Process Automation**: Generative AI can be used to automate repetitive business processes such as data entry, invoice processing, and customer onboarding.\n",
      "9. **Customer Segmentation**: Generative AI can be used to segment customers based on their behavior, preferences, and demographics. This can help businesses tailor their marketing efforts to specific groups of customers.\n",
      "10. **Financial Analysis**: Generative AI can be used to analyze financial data and make predictions about future trends and patterns. This can help businesses anticipate changes in the market and make informed investment decisions.\n",
      "\n",
      "Some of the key industries that are leveraging Generative AI include:\n",
      "\n",
      "1. **Finance and Banking**: Generative AI is being used to automate loan applications, detect credit risk, and predict stock market trends.\n",
      "2. **Healthcare**: Generative AI is being used to analyze medical images, diagnose diseases, and develop personalized treatment plans.\n",
      "3. **Retail**: Generative AI is being used to personalize product recommendations, optimize supply chain logistics, and create immersive brand experiences.\n",
      "4. **Marketing and Advertising**: Generative AI is being used to create personalized ad campaigns, optimize marketing spend, and analyze customer behavior.\n",
      "5. **Manufacturing**: Generative AI is being used to design new products, optimize production processes, and predict maintenance needs.\n",
      "\n",
      "Overall, the applications of Generative AI are vast and varied, and it's likely that we'll see even more innovative uses in the future.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: AI-powered tools can generate high-quality content such as:\n",
      "\t* Product descriptions and blog posts\n",
      "\t* Social media posts and tweets\n",
      "\t* Infographics and presentations\n",
      "\t* Music, audio tracks, and podcasts\n",
      "2. **Marketing Automation**: Generative AI allows for personalized customer experiences through:\n",
      "\t* Email campaigns and automation\n",
      "\t* Chatbots and virtual assistants\n",
      "\t* Recommendation engines and product suggestions\n",
      "3. **Design and Architecture**: AI can assist with:\n",
      "\t* Building design, layout, and mockups\n",
      "\t* Fashion design, style, and trend prediction\n",
      "\t* Product designs, packaging, and branding\n",
      "4. **Customer Service**: Generative AI enables:\n",
      "\t* 24/7 customer support chatbots\n",
      "\t* Personalized customer responses through AI-driven writing tools\n",
      "\t* Speech recognition for voice-based support systems\n",
      "5. **Sales Forecasting and Pipeline Management**: AI can analyze performance metrics to predict sales trends, identify potential bottlenecks, and streamline lead nurturing.\n",
      "6. **Research and Development**: Generative AI accelerates scientific discovery by generating:\n",
      "\t* Literature reviews and research summaries\n",
      "\t* Data visualization and insights\n",
      "\t* Experiment designs and hypothesis generation\n",
      "7. **Compliance and Risk Management**: AI-powered tools can help identify potential regulatory risks, detect unusual activity patterns, and automate reporting workflows.\n",
      "8. **Financial Analysis and Reporting**: AI can process large sets of financial data to:\n",
      "\t* Analyze market trends and predict future developments\n",
      "\t* Identify high-risk investments or areas for improvement\n",
      "\t* Automate financial statement analysis and generation\n",
      "9. **Content Recommendations**: Generative AI helps users find relevant content across different platforms through personalized suggestions, such as:\n",
      "\t* Video recommendations on streaming services\n",
      "\t* Music playlists based on user preferences\n",
      "10. **Education and Learning**: AI-powered tools create customized learning experiences by generating:\n",
      "\t* Adaptive assessments and quizzes\n",
      "\t* Personalized recommendations for learning materials\n",
      "\t* Automated grading and feedback systems\n",
      "\n",
      "These applications of generative AI can help businesses boost efficiency, improve accuracy, and enhance customer experiences across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand the core concepts behind Low-LFast-R (LLFR) models. From what I remember in my AI class, LLMs are machine learning models specifically designed to simulate human level understanding or even surpass it in some complex tasks. That makes me think that they can handle a lot more than just language processing.\n",
      "\n",
      "Starting with 'neural network,' this seems quite technical but I know neural networks are composed of layers of interconnected nodes or units, which process information using activation functions like sigmoid or ReLU. In the context of LLMs, they probably layer the information in some way that mimics human thought processes—like recognizing, understanding, and remembering.\n",
      "\n",
      "Now, for 'attention.' I've heard this term used in contexts where machines need to focus on certain parts of input data more than others. I think it's about allowing models to weigh inputs based on their relevance or importance. For example, when translating a sentence, the model might focus more on important words than others because they contribute significantly to the meaning.\n",
      "\n",
      "The 'transformer' is another big part here. From what I recall, transformers process information sequentially without needing to compute the entire input at once. This is especially useful for sequential data like text or time series. They break data into segments and learn dependencies over time, which makes them very flexible but computationally intensive compared to some other architectures.\n",
      "\n",
      "Putting it all together, an LLM uses layers of neural networks, possibly with attention mechanisms that allow the model to focus on relevant parts of input text, and each part processes information sequentially. The transformers are particularly good at handling sequential data without requiring all data upfront, making them suitable for various complex tasks beyond just language understanding.\n",
      "\n",
      "Wait, but how do these components work together exactly? I think each layer or sublayer in a neural network might receive some attention from different layers. Perhaps the embeddings provide initial feature representations, and then the transformer applies self-attention to sequence data. The presence of multiple hidden layers allows the model to learn higher-level features, which is essential for deep understanding.\n",
      "\n",
      "Also, I remember something about the word \"LLF.\" Maybe it's short for Low Lookup Function or refers to models that can efficiently look up contexts or make approximate inferences without processing everything each time they're queried. But how does that tie into the other concepts?\n",
      "\n",
      "If attention mechanisms are key for focusing on important parts of data, maybe 'Low Lookup' allows the model to recall relevant features quickly, reducing computational requirements. Transformers could also be optimized for efficiency, especially when combined with parallelizable computations. Perhaps LLMs like CLIP or GPT use these components in combination to handle both detailed understanding and efficient processing.\n",
      "\n",
      "In summary, to break it down:\n",
      "\n",
      "- Neural network: The broad structure of the model.\n",
      "- Attention: Mechanisms allowing focused relevance in input data.\n",
      "- Transformer: Processing sequential data with segment-based weights without simultaneous computation for efficiency.\n",
      "\n",
      "Together, they form a system that can learn patterns, focus on important aspects through attention, and handle sequential information efficiently through transformers. This combination works together to enable the complex capabilities of LLMs in tasks like text comprehension, summarization, and even handling mathematical proofs.\n",
      "</think>\n",
      "\n",
      "**Understanding Core Concepts in Low-LFast-R (LLFR) Models**\n",
      "\n",
      "Low-LFast-R (LLFR) models are advanced machine learning architectures designed for high-level understanding and efficient processing. Here's a breakdown of their core components:\n",
      "\n",
      "1. **Neural Network**: The layered structure composed of interconnected nodes, akin to neurons in the brain, using activation functions like sigmoid or ReLU. These networks process information through sequences, units, features, and representations.\n",
      "\n",
      "2. **Attention Mechanisms**: Enable the model to focus on relevant parts of input data by weighing their importance during processing. This is crucial for tasks requiring context-aware reasoning.\n",
      "\n",
      "3. **Transformer Architecture**: Processes sequential data without simultaneous computation by breaking it into segments with self-attention mechanisms that learn temporal dependencies, offering flexibility and efficiency.\n",
      "\n",
      "**Combined Functionality:**\n",
      "\n",
      "- Each layer within the model may leverage attention from different layers, and embeddings provide initial feature representations.\n",
      "- The transformer operates on segment-based weights for sequences, enhancing its suitability for various complex tasks beyond language processing.\n",
      "\n",
      "**Efficiency and Focus:**\n",
      "\n",
      "- 'Low Lookup' functions allow inferences based on context quickly, reducing computational need. Transformers might use parallelization to enhance efficiency.\n",
      "- LLMs like CLIP or GPT integrate attention and transformers to balance detailed understanding with efficient processing, capable of handling tasks from text comprehension to mathematical proofs.\n",
      "\n",
      "In essence, LLFR models combine neural network structure, advanced attention, and transformer processing, enabling their unique capabilities in complex AI tasks.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
